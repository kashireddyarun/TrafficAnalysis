"""
Test suite for the Traffic Analysis System - Testing Available Components
Tests the components that are currently implemented
"""

import unittest
import numpy as np
import tempfile
import os
import sys
from pathlib import Path

# Add src to path for imports
sys.path.append(str(Path(__file__).parent.parent))

# Import only the modules that exist and work
from src.traffic_system.congestion_detector import CongestionDetector, CongestionMetrics
from src.traffic_system.signal_optimizer import SignalOptimizer, TrafficDemand
from src.traffic_system.analytics import TrafficAnalytics
from src.utils.config import load_config, get_default_config

class TestCongestionDetector(unittest.TestCase):
    """Test cases for CongestionDetector"""
    
    def setUp(self):
        """Set up test fixtures"""
        self.config = {
            'congestion': {
                'density_threshold': 0.7,
                'speed_threshold': 5,
                'time_window': 30
            }
        }
        self.detector = CongestionDetector(self.config)
        
    def test_density_calculation(self):
        """Test vehicle density calculation"""
        detections = [
            {'bbox': [100, 100, 150, 150]},
            {'bbox': [200, 200, 250, 250]},
            {'bbox': [300, 300, 350, 350]}
        ]
        
        zone_area = 10000  # 100x100 area
        density = self.detector.calculate_density(detections, zone_area)
        
        self.assertEqual(density, 3 / 10000)
        
    def test_congestion_level_detection(self):
        """Test congestion level classification"""
        # High congestion scenario
        metrics = CongestionMetrics(
            density=0.8,
            average_speed=3.0,
            congestion_level="",
            flow_rate=10.0,
            occupancy_ratio=0.9,
            timestamp=1234567890
        )
        
        level = self.detector.detect_congestion_level(metrics)
        self.assertIn(level, ['low', 'medium', 'high', 'severe'])
        
    def test_occupancy_ratio_calculation(self):
        """Test occupancy ratio calculation"""
        detections = [
            {'bbox': [0, 0, 100, 100]},  # 10000 pixel area
            {'bbox': [200, 200, 250, 250]}  # 2500 pixel area
        ]
        
        zone_bounds = ((0, 0), (400, 400))  # 160000 pixel area
        occupancy = self.detector.calculate_occupancy_ratio(detections, zone_bounds)
        
        expected_occupancy = (10000 + 2500) / 160000
        self.assertAlmostEqual(occupancy, expected_occupancy, places=6)
        
    def test_speed_patterns_analysis(self):
        """Test speed pattern analysis"""
        tracks = [
            {'speed': 25, 'track_id': 1},
            {'speed': 30, 'track_id': 2},
            {'speed': 2, 'track_id': 3},  # Slow vehicle
            {'speed': 35, 'track_id': 4}
        ]
        
        analysis = self.detector.analyze_speed_patterns(tracks)
        
        self.assertGreater(analysis['average_speed'], 0)
        self.assertEqual(analysis['slow_vehicles'], 1)  # One vehicle < 5 km/h
        self.assertIsInstance(analysis['speed_distribution'], list)

class TestSignalOptimizer(unittest.TestCase):
    """Test cases for SignalOptimizer"""
    
    def setUp(self):
        """Set up test fixtures"""
        self.config = {
            'traffic_management': {
                'signal_optimization': {
                    'min_green_time': 10,
                    'max_green_time': 60
                }
            }
        }
        self.optimizer = SignalOptimizer(self.config)
        
    def test_traffic_demand_calculation(self):
        """Test traffic demand calculation"""
        # The SignalOptimizer uses a simplified direction filtering
        # Let's test with detections that will be counted
        detections = [
            {'bbox': [100, 100, 150, 150]},
            {'bbox': [200, 200, 250, 250]}
        ]
        tracks = [
            {'track_id': 1, 'speed': 25},
            {'track_id': 2, 'speed': 30}
        ]
        
        demand = self.optimizer.calculate_traffic_demand(detections, tracks, 'north_south')
        
        # Test that the demand object is created correctly
        self.assertIsInstance(demand, TrafficDemand)
        self.assertEqual(demand.direction, 'north_south')
        self.assertGreaterEqual(demand.vehicle_count, 0)  # Should be non-negative
        self.assertGreaterEqual(demand.average_speed, 0)  # Should be non-negative
        
    def test_adaptive_optimization(self):
        """Test adaptive signal optimization"""
        demands = {
            'north_south': TrafficDemand(
                vehicle_count=10,
                queue_length=5,
                average_speed=15,
                waiting_time=20,
                direction='north_south'
            ),
            'east_west': TrafficDemand(
                vehicle_count=5,
                queue_length=2,
                average_speed=25,
                waiting_time=10,
                direction='east_west'
            )
        }
        
        timing = self.optimizer._adaptive_optimization(demands)
        
        # North-south should get longer green time due to higher demand
        self.assertGreater(timing['north_south'].green_time, timing['east_west'].green_time)
        
    def test_webster_optimization(self):
        """Test Webster's optimization method"""
        demands = {
            'north_south': TrafficDemand(
                vehicle_count=8,
                queue_length=3,
                average_speed=20,
                waiting_time=15,
                direction='north_south'
            ),
            'east_west': TrafficDemand(
                vehicle_count=12,
                queue_length=6,
                average_speed=18,
                waiting_time=25,
                direction='east_west'
            )
        }
        
        timing = self.optimizer._webster_optimization(demands)
        
        # Should return valid timing for both directions
        self.assertIn('north_south', timing)
        self.assertIn('east_west', timing)
        self.assertGreaterEqual(timing['north_south'].green_time, self.optimizer.min_green_time)
        self.assertLessEqual(timing['north_south'].green_time, self.optimizer.max_green_time)

class TestTrafficAnalytics(unittest.TestCase):
    """Test cases for TrafficAnalytics"""
    
    def setUp(self):
        """Set up test fixtures"""
        self.config = {}
        # Use temporary database for testing
        self.temp_db = tempfile.NamedTemporaryFile(suffix='.db', delete=False)
        self.analytics = TrafficAnalytics(self.config, self.temp_db.name)
        
    def tearDown(self):
        """Clean up test fixtures"""
        self.temp_db.close()
        if os.path.exists(self.temp_db.name):
            os.unlink(self.temp_db.name)
        
    def test_vehicle_detection_logging(self):
        """Test vehicle detection logging"""
        detection = {
            'class': 'car',
            'confidence': 0.9,
            'bbox': [100, 100, 200, 200],
            'speed': 25.0,
            'direction': 'north',
            'lane': 'lane1'
        }
        
        # Should not raise an exception
        try:
            self.analytics.log_vehicle_detection(detection)
            success = True
        except Exception:
            success = False
            
        self.assertTrue(success)
        
    def test_traffic_flow_logging(self):
        """Test traffic flow logging"""
        flow_data = {
            'vehicle_count': 10,
            'average_speed': 30.0,
            'peak_speed': 45.0,
            'congestion_level': 'medium',
            'flow_rate': 15.0
        }
        
        # Should not raise an exception
        try:
            self.analytics.log_traffic_flow(flow_data)
            success = True
        except Exception:
            success = False
            
        self.assertTrue(success)
        
    def test_analytics_report_generation(self):
        """Test analytics report generation"""
        # Log some test data first
        for i in range(5):
            detection = {
                'class': 'car',
                'confidence': 0.8 + i * 0.02,
                'bbox': [100 + i*10, 100, 200 + i*10, 200],
                'speed': 20.0 + i * 2,
                'direction': 'north',
                'lane': 'lane1'
            }
            self.analytics.log_vehicle_detection(detection)
            
        report = self.analytics.generate_comprehensive_report('hourly')
        
        self.assertIsNotNone(report)
        self.assertEqual(report.period, 'hourly')
        self.assertIsInstance(report.recommendations, list)

class TestConfigUtilities(unittest.TestCase):
    """Test cases for configuration utilities"""
    
    def test_default_config_loading(self):
        """Test loading default configuration"""
        config = get_default_config()
        
        self.assertIsInstance(config, dict)
        self.assertIn('model', config)
        self.assertIn('classes', config)
        self.assertIn('tracking', config)
        
    def test_config_validation(self):
        """Test configuration validation"""
        from src.utils.config import validate_config
        
        valid_config = get_default_config()
        self.assertTrue(validate_config(valid_config))
        
        # Test invalid config
        invalid_config = {'model': {'confidence_threshold': 1.5}}  # Invalid threshold
        self.assertFalse(validate_config(invalid_config))
        
    def test_config_update(self):
        """Test configuration update functionality"""
        from src.utils.config import update_config
        
        base_config = {'model': {'name': 'yolov8n', 'confidence': 0.5}}
        updates = {'model': {'confidence': 0.7}, 'new_section': {'value': 42}}
        
        updated = update_config(base_config, updates)
        
        self.assertEqual(updated['model']['confidence'], 0.7)
        self.assertEqual(updated['model']['name'], 'yolov8n')  # Should preserve
        self.assertEqual(updated['new_section']['value'], 42)

class TestSystemIntegration(unittest.TestCase):
    """Integration tests for available components"""
    
    def setUp(self):
        """Set up test fixtures"""
        self.config = get_default_config()
        
    def test_component_integration(self):
        """Test integration between available components"""
        # Initialize components
        congestion_detector = CongestionDetector(self.config)
        signal_optimizer = SignalOptimizer(self.config)
        
        # Create mock data
        mock_detections = [
            {'bbox': [100, 100, 200, 200], 'confidence': 0.9, 'class': 'car'}
            for _ in range(5)
        ]
        
        mock_tracks = [
            {'track_id': i, 'speed': 20 + i*5, 'direction': 'north_south'}
            for i in range(5)
        ]
        
        # Test congestion analysis
        frame_area = 640 * 480
        congestion_metrics = congestion_detector.analyze_congestion(
            mock_detections, mock_tracks, frame_area
        )
        
        # Test signal optimization
        signal_timing = signal_optimizer.optimize_signals(mock_detections, mock_tracks)
        
        # Verify results
        self.assertIsInstance(congestion_metrics, CongestionMetrics)
        self.assertIsInstance(signal_timing, dict)
        self.assertIn(congestion_metrics.congestion_level, ['low', 'medium', 'high', 'severe'])

def create_test_suite():
    """Create test suite with available components"""
    
    suite = unittest.TestSuite()
    
    # Add test cases for components we have
    suite.addTest(unittest.makeSuite(TestCongestionDetector))
    suite.addTest(unittest.makeSuite(TestSignalOptimizer))
    suite.addTest(unittest.makeSuite(TestTrafficAnalytics))
    suite.addTest(unittest.makeSuite(TestConfigUtilities))
    suite.addTest(unittest.makeSuite(TestSystemIntegration))
    
    return suite

def run_tests():
    """Run all available tests"""
    suite = create_test_suite()
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    print(f"\nTest Results:")
    print(f"Tests run: {result.testsRun}")
    print(f"Failures: {len(result.failures)}")
    print(f"Errors: {len(result.errors)}")
    
    if result.testsRun > 0:
        success_rate = (result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100
        print(f"Success rate: {success_rate:.1f}%")
    
    # Print details about failures and errors
    if result.failures:
        print(f"\nFailures:")
        for test, traceback in result.failures:
            print(f"- {test}: {traceback.split('AssertionError:')[-1].strip()}")
    
    if result.errors:
        print(f"\nErrors:")
        for test, traceback in result.errors:
            print(f"- {test}: {traceback.split('Error:')[-1].strip()}")
    
    return result.wasSuccessful()

if __name__ == '__main__':
    print("Running Traffic Analysis System Tests...")
    print("Testing available components: CongestionDetector, SignalOptimizer, Analytics, Config")
    print("=" * 70)
    
    success = run_tests()
    
    if success:
        print("\nüéâ All tests passed! Your traffic analysis system components are working correctly.")
        print("\nNext steps:")
        print("1. Install required packages: pip install -r requirements.txt")
        print("2. Test with sample data: python main.py --source 0")
        print("3. Launch dashboard: streamlit run src/app/streamlit_app.py")
    else:
        print("\n‚ö†Ô∏è  Some tests failed. Please check the error messages above.")
    
    sys.exit(0 if success else 1)
